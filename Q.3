import pandas as pd
import numpy as np

# Set a seed for reproducibility
np.random.seed(42)

# Create a data frame with 3 columns and 50 rows
data = {
    'Column1': np.random.rand(50),
    'Column2': np.random.rand(50),
    'Column3': np.random.rand(50)
}

df = pd.DataFrame(data)

# Replace 10% of the values with null values
null_indices = np.random.choice(df.size, size=int(0.1 * df.size), replace=False)
df.values.flat[null_indices] = np.nan

# Display the original data frame
print("Original DataFrame:\n", df)

# Program a
# Identify and count missing values in the data frame
missing_values = df.isnull()
missing_count = missing_values.sum().sum()
print("\nMissing Values Count:\n", missing_count)

# Program b
# Drop the column having more than 5 null values
df = df.dropna(thresh=len(df) - 5, axis=1)
print("\nDataFrame after dropping columns with more than 5 null values:\n", df)

# Program c
# Identify the row label having the maximum sum of all values and drop that row
max_sum_row_label = df.sum(axis=1).idxmax()
df = df.drop(index=max_sum_row_label)
print("\nDataFrame after dropping the row with the maximum sum of values:\n", df)

# Program d
# Sort the data frame based on the first column
df = df.sort_values(by='Column1')
print("\nDataFrame sorted on the basis of the first column:\n", df)

# Program e
# Remove duplicates from the first column
df = df.drop_duplicates(subset='Column1')
print("\nDataFrame after removing duplicates from the first column:\n", df)

# Program f
# Find the correlation between the first and second column
correlation = df['Column1'].corr(df['Column2'])
print("\nCorrelation between the first and second column:\n", correlation)

# Program g
# Find the covariance between the second and third column
covariance = df['Column2'].cov(df['Column3'])
print("\nCovariance between the second and third column:\n", covariance)

# Program h
# Discretize the second column and create 5 bins
df['Column2_bins'] = pd.cut(df['Column2'], bins=5)
print("\nDataFrame with discretized second column:\n", df)
